# Networking status report May 14, 2018

## Recent accomplishments

### Logic/Diffusion split

Coupling of the blockchain logic and networking definitions has been greatly
reduced since the advent of the [Logic/Diffusion split](https://github.com/input-output-hk/cardano-sl/pull/2154)
merged on February 1.

- The interface to the networking side is explicitly defined in one place,
  and the abstraction is much stronger than it was prior. We can now make
  changes to a network implementation without conflicting with work on other,
  unrelated areas.
- A particular network implementation can be run in isolation. This is a boon
  for testing, benchmarking, and simulation, which were heretofore very
  difficult if not impossible to do.

### Block (de)serialisation 

There was a longstanding design flaw: verification was included in
deserialisation, so that, for example, reading a block from a stream of
bytes would also verify that block. The intensions behind this were good: to
ensure that no invalid (yet well-formed) block could ever come to be. But this
was a bad choice, because

- Invalid blocks (and other datatypes) are legitimate things which we do want
  to deal with, in testing among other areas.
- The network layer should not deal with verification, which is a higher
  level concern.
- Verification is expensive, so building it into deserialisation will slow down
  the network layer.

In a line: well-formedness and validity are independent notions, and so they
should be treated as such.

A [fix](https://github.com/input-output-hk/cardano-sl/pull/2324) was merged on
February 20 after much debate with former collaborators, who disagreed with
the change.

### Block streaming download

We have implemented a streaming block download. In contrast to the existing
method, which uses batches of 2200 blocks, interleaved with verification and
application, the streaming method verifies and applies blocks as they are
downloaded.

Performance tests from relays across the globe shows that sync time is
expected to be reduced to between 50% to 20% of the old batching sync time.
Users with poor network connections should experience the most improvement.

The block streaming implementation pushes the bottleneck from the network to
the client CPU.


### Block verification and application

We have begun to study the performance of block verification and application,
which along with block streaming determines speed of an initial download when
the user starts up their wallet frontend.

Currently block verification is using byte size limits of headers and blocks.
This is unfortunate design decision, since now verification also serializes the
headers and blocks to compute the sizes.  We also discovered that a similar
idea is used in computation of sizes of transactions (which is used to compute
fees).  We think that ultimately all sizes should be specified using structured
data, i.e. number of transactions, etc.  For transactions this is also
unfortunate, because transaction addresses are serialized together with their
hash which byte size can vary, and cannot be determined other than computing
the hash, which is expensive.  However, switching from byte sizes to structured
sizes require protocol changes that may lead to a hard fork.

We developed benchmarks for verification of headers, blocks and application of
blocks and we developed an executable which let us profile block verification
and application using standard ghc profiling tools.

The benchmarks suggest, as we suspected, that we should remove serialization of
headers/blocks in validation.  Our initial approach was to add a method which
calculated the binary sizes of structures, but the improvements we measured
were not as expected and the benchmarks and profiling data suggested that
verification still spends too much time in serialization which should be
improved.  Currently, Duncan Coutts is working on changes in the CBORG library
which we are using for binary encoding/decoding.  The changes will allow us to
retain binary data corresponding to de-serialized (sub-)structures.  Using it
we will be able to avoid re-serialization of blocks, headers, and many other
sub-structures.  This will allow us to speed up computation of sizes and
hashes, which will not require serialization.  We expect, based on the
profiling data, that this will gives us performance boost we are looking for.

### Peer discovery

The peer discovery system, formerly an implementation of the Kademlia protocol
with a few ad-hoc extra features, [has been
rewritten](https://github.com/arybczak/peer-discovery).  It is still based on
Kademlia, but does not have features unnecessary for our purposes, and includes
changes to address well-known security flaws in the original design.

The first iteration is ready for testing and integration into cardano-sl after a
minor detail related to security in the maintanance of the routing table bit is
fixed.

Detailed description of the protocol and its characteristics can be found
[here](https://github.com/arybczak/peer-discovery/blob/master/peer-discovery.md).

### CBOR

There were a few ommisions related to checks for canonicity of the CBOR form in
primitive decoders used in cborg library as well as a bug allowing for
construction of invalid Haskell object (ByteString) if a specific, hand-crafted
string of bytes was supplied to the decoder.

The bug and the ommissions were fixed in the cborg library. CBOR canonicity
tests in cardano-sl testsuite were extended to check for the missing cases.

### Stack LTS upgrade

We're using LTS-9.1, released nearly one year ago on August 16, 2017, and GHC
8.0.2. There's
a [patch](https://github.com/input-output-hk/cardano-sl/pull/2745)
which brings us to LTS-11.2 and GHC 8.2.2. It's ready, working, approved and
strongly desired by multiple collaborators. It comes, among other things, with
important bug fixes in the `async` package. It's held up by problems with CI
and nix, which must be resolved by devops.

## Testing and simulation

As stated earlier, testing and simulation of the network layer are now feasible.
No testing strategy has been developed and test coverage is minimal. New
features such as block streaming download will come with test coverage and
simulations to compare performance with the existing batched implementation.

## Protocol documentation

The [protocol documentation](https://cardanodocs.com/) has not been updated.
All of the sections under "Protocols" are probably out-of-date and require
attention.

## The immediate future

### Shelley

Once we have integrated block streaming and are satisfied with its performance
and that of verification and application, we can begin to concentrate on
Shelley requirements.

#### Peer discovery

This is nearly ready to be integrated into cardano-sl.
The plan is to ship it activated but unused, which will allow us to gather
information about the shape of the P2P network, while still relying on the
existing centralised discovery method.

### Other work: remnants of the old design

#### Recovery mode

This part of the system needs to be completely redone. To summarize:
if a node so much as receives a block header which is not an immediate
continuation of its own tip, it enters the dreaded "recovery mode", disabling
a bunch of normal operating features until it either downloads, verifies, and
applies the entire chain up to that block, or receives another, more
difficult block headers and downloads the entire chain up to _that_ block.

#### `Worker` model, `InSpecs` and `OutSpecs`

The old design (present since before any of the current members of the
networking workstream were with IOHK) would derive the network protocol from
the set of "Worker"s and "Listener"s. This never made any sense from an
architectural point of view: the blockchain logic should work with an
abstraction of a network, rather than stipulate how that network abstraction
should work under-the-hood. This was rectified by the logic/diffusion split
but impotent remnants of the old design remain. These serve only to confuse
developers, and so should be removed. CSL-2337.

### Protocol versioning

Currently the protocol version determiner is a record of potentially unbounded
size including the blockchain magic number, the blockchain version, and the
in- and out-handler identifiers. Problems:

- The latter two things are of potentially unbounded size.
- The blockchain protocol magic has nothing to do with the software or protocol
  version.
- The blockchain version has nothing to do with the software or protocol version.
- The actual protocol version is not included.

We need to come up with a strategy to deprecate this thing, and use instead a
protocol version number, while still supporting the old record until all user
software can be upgraded.

### Reflection configurations

In the beginning, template Haskell was used to bake-in protocol constants at
compile time (decision made before anyone on this team was with IOHK). This
implied that

- A single cardano executable could interpret only one blockchain. It was
  impossible for one executable to, for instance, deal with both a mainnet and
  a testnet blockchain.
- It made testing and simulation either slow or impossible, because trying a
  run with a different configuration parameter required rebuilding the
  software.

The second point was addressed by using reflection configurations instead, but
the first point is only slightly less bad. Now a single cardano process can
interpret only one blockchain. You can use it on different *nets, but you have
to restart the program.

Anyway, the poor design remains: protocol constants should not be treated as
statically known values, because they are not. This has been fixed in the
networking layer, but remains unaddressed in the rest of the software.
Alex Vieth can fix it but it will be time consuming.
